{
	"httpRequest": {
		"method": "POST",
		"path": "/v1/messages",
		"body": {
			"contentType": "application/json",
			"type": "JSON",
			"json": {
				"model": "claude-sonnet-4-5-20250929",
				"temperature": 0,
				"stream": false,
				"max_tokens": 16000,
				"tools": [
					{
						"name": "get_documentation",
						"description": "Retrieve documentation to guide workflow building.\n\nTYPE: best_practices\nUse when you need guidance on workflow patterns and implementation.\nRequires: techniques array (workflow techniques to get practices for)\nReturns: Best practices including recommended nodes, common pitfalls, performance tips.\n\nTYPE: node_recommendations\nUse when user wants AI capabilities but doesn't specify exact nodes/providers.\nRequires: categories array (task categories to get recommendations for)\nReturns: Default node recommendations with alternatives.\n\nDo NOT use node_recommendations when:\n- User explicitly names a provider (e.g., \"use Claude\", \"with OpenAI\", \"using Gemini\")\n- User specifies exact node names\n\nAvailable techniques for best_practices:\n- trigger, loop, branch, subroutine, pagination, parallel_execution, error_handling, scheduling, rate_limiting, batch_processing, ai_agent, ai_chain, rag, data_transformation, http_request\n\nAvailable categories for node_recommendations:\n- text_manipulation: summarization, analysis, extraction, classification, chat\n- image_generation: generate, analyze, edit images\n- video_generation: create videos from text/images\n- audio_generation: text-to-speech, transcription, translation",
						"input_schema": {
							"type": "object",
							"properties": {
								"requests": {
									"type": "array",
									"items": {
										"anyOf": [
											{
												"type": "object",
												"properties": {
													"type": {
														"type": "string",
														"const": "best_practices"
													},
													"techniques": {
														"type": "array",
														"items": {
															"type": "string",
															"enum": [
																"scheduling",
																"chatbot",
																"form_input",
																"scraping_and_research",
																"monitoring",
																"enrichment",
																"triage",
																"content_generation",
																"document_processing",
																"data_extraction",
																"data_analysis",
																"data_transformation",
																"data_persistence",
																"notification",
																"knowledge_base",
																"human_in_the_loop"
															]
														},
														"minItems": 1,
														"description": "Workflow techniques to get best practices for"
													}
												},
												"required": ["type", "techniques"],
												"additionalProperties": false
											},
											{
												"type": "object",
												"properties": {
													"type": {
														"type": "string",
														"const": "node_recommendations"
													},
													"categories": {
														"type": "array",
														"items": {
															"type": "string",
															"enum": [
																"text_manipulation",
																"image_generation",
																"video_generation",
																"audio_generation"
															]
														},
														"minItems": 1,
														"description": "Task categories to get node recommendations for"
													}
												},
												"required": ["type", "categories"],
												"additionalProperties": false
											}
										]
									},
									"minItems": 1,
									"description": "Array of documentation requests to retrieve"
								}
							},
							"required": ["requests"],
							"additionalProperties": false,
							"$schema": "http://json-schema.org/draft-07/schema#"
						}
					},
					{
						"name": "search_nodes",
						"description": "Search for n8n nodes by name or find sub-nodes that output specific connection types. Use this before adding nodes to find the correct node types.\n\nSearch modes:\n1. Name search (default): Search nodes by name/description\n   Example: { queryType: \"name\", query: \"http\" }\n\n2. Sub-node search: Find sub-nodes that output specific AI connection types\n   Example: { queryType: \"subNodeSearch\", connectionType: NodeConnectionTypes.AiTool }\n   With optional query filter: { queryType: \"subNodeSearch\", connectionType: NodeConnectionTypes.AiTool, query: \"calculator\" }\n   This finds sub-nodes (like \"Calculator Tool\") that can be connected to nodes accepting that connection type\n\nCommon AI connection types for sub-node search:\n- NodeConnectionTypes.AiLanguageModel (finds LLM provider sub-nodes like \"OpenAI Chat Model\")\n- NodeConnectionTypes.AiTool (finds tool sub-nodes like \"Calculator Tool\", \"Code Tool\")\n- NodeConnectionTypes.AiMemory (finds memory sub-nodes like \"Window Buffer Memory\")\n- NodeConnectionTypes.AiEmbedding (finds embedding sub-nodes like \"Embeddings OpenAI\")\n- NodeConnectionTypes.AiVectorStore (finds vector store sub-nodes)\n- NodeConnectionTypes.AiDocument (finds document loader sub-nodes)\n- NodeConnectionTypes.AiTextSplitter (finds text splitter sub-nodes)\n\nYou can search for multiple different criteria at once by providing an array of queries.",
						"input_schema": {
							"type": "object",
							"properties": {
								"queries": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"queryType": {
												"type": "string",
												"enum": ["name", "subNodeSearch"],
												"description": "Type of search to perform"
											},
											"query": {
												"type": "string",
												"description": "Search term to filter results"
											},
											"connectionType": {
												"type": "string",
												"enum": [
													"ai_agent",
													"ai_chain",
													"ai_document",
													"ai_embedding",
													"ai_languageModel",
													"ai_memory",
													"ai_outputParser",
													"ai_retriever",
													"ai_reranker",
													"ai_textSplitter",
													"ai_tool",
													"ai_vectorStore",
													"main"
												],
												"description": "For subNodeSearch: connection type like ai_languageModel, ai_tool, etc."
											}
										},
										"required": ["queryType"],
										"additionalProperties": false
									},
									"minItems": 1,
									"description": "Array of search queries to find different types of nodes"
								}
							},
							"required": ["queries"],
							"additionalProperties": false,
							"$schema": "http://json-schema.org/draft-07/schema#"
						}
					},
					{
						"name": "get_node_details",
						"description": "Get detailed information about a specific n8n node type including properties, available connections, and up to 5 example configurations. Use this before adding nodes to understand their input/output structure.",
						"input_schema": {
							"type": "object",
							"properties": {
								"nodeName": {
									"type": "string",
									"description": "The exact node type name (e.g., n8n-nodes-base.httpRequest)"
								},
								"nodeVersion": {
									"type": "number",
									"description": "The exact node version"
								},
								"withParameters": {
									"type": "boolean",
									"default": false,
									"description": "Whether to include node parameters in the output"
								},
								"withConnections": {
									"type": "boolean",
									"default": true,
									"description": "Whether to include node supported connections in the output"
								}
							},
							"required": ["nodeName", "nodeVersion"],
							"additionalProperties": false,
							"$schema": "http://json-schema.org/draft-07/schema#"
						}
					},
					{
						"name": "submit_discovery_results",
						"description": "Submit the final discovery results",
						"input_schema": {
							"type": "object",
							"properties": {
								"nodesFound": {
									"type": "array",
									"items": {
										"type": "object",
										"properties": {
											"nodeName": {
												"type": "string",
												"description": "The internal name of the node (e.g., n8n-nodes-base.gmail)"
											},
											"version": {
												"type": "number",
												"description": "The version number of the node (e.g., 1, 1.1, 2, 3, 3.2, etc.)"
											},
											"reasoning": {
												"type": "string",
												"description": "Why this node is relevant for the workflow"
											},
											"connectionChangingParameters": {
												"type": "array",
												"items": {
													"type": "object",
													"properties": {
														"name": {
															"type": "string",
															"description": "Parameter name (e.g., \"mode\", \"operation\", \"hasOutputParser\")"
														},
														"possibleValues": {
															"type": "array",
															"items": {
																"type": ["string", "boolean", "number"]
															},
															"description": "Possible values this parameter can take"
														}
													},
													"required": ["name", "possibleValues"],
													"additionalProperties": false
												},
												"description": "Parameters that affect node connections (inputs/outputs). ONLY include if parameter appears in <input> or <output> expressions"
											}
										},
										"required": [
											"nodeName",
											"version",
											"reasoning",
											"connectionChangingParameters"
										],
										"additionalProperties": false
									},
									"description": "List of n8n nodes identified as necessary for the workflow"
								}
							},
							"required": ["nodesFound"],
							"additionalProperties": false,
							"$schema": "http://json-schema.org/draft-07/schema#"
						}
					}
				],
				"thinking": {
					"type": "disabled"
				},
				"messages": [
					{
						"role": "user",
						"content": "Create an automation that runs on Monday mornings. It reads my Gmail inbox from the weekend, analyzes them with `gpt-4.1-mini` to find action items and priorities, and emails me a structured email using Gmail."
					},
					{
						"role": "user",
						"content": [
							{
								"type": "text",
								"text": "<user_request>\n\nCreate an automation that runs on Monday mornings. It reads my Gmail inbox from the weekend, analyzes them with `gpt-4.1-mini` to find action items and priorities, and emails me a structured email using Gmail.\n\n</user_request>",
								"cache_control": {
									"type": "ephemeral"
								}
							}
						]
					}
				],
				"system": [
					{
						"type": "text",
						"text": "<role>\nYou are a Discovery Agent for n8n AI Workflow Builder.\n\nYOUR ROLE: Identify relevant n8n nodes and their connection-changing parameters.\n</role>\n\n<available_tools>\n- get_documentation: Retrieve best practices and/or node recommendations. Pass an array of requests, each with type \"best_practices\" (requires techniques array) or \"node_recommendations\" (requires categories array)\n- search_nodes: Find n8n nodes by keyword\n- get_node_details: Get complete node information including <connections>\n- submit_discovery_results: Submit final results\n</available_tools>\n\n<process>\n1. **Analyze user prompt** - Extract services, models, and technologies mentioned\n2. **Call get_documentation** with requests array containing best_practices (with techniques) and optionally node_recommendations (with categories for AI tasks)\n3. **Identify workflow components** from user request, best practices\n4. **Call search_nodes IN PARALLEL** for all components (e.g., \"Gmail\", \"OpenAI\", \"Schedule\")\n5. **Call get_node_details IN PARALLEL** for ALL promising nodes (batch multiple calls)\n6. **Extract node information** from each node_details response:\n   - Node name from <name> tag\n   - Version number from <version> tag (required - extract the number)\n   - Connection-changing parameters from <connections> section\n7. **Call submit_discovery_results** with complete nodesFound array\n</process>\n\n<technique_categorization>\nWhen calling get_documentation with type: \"best_practices\", select techniques that match the user's workflow intent.\n\n<available_techniques>\n- **scheduling**: Running an action at a specific time or interval\n- **chatbot**: Receiving chat messages and replying (built-in chat, Telegram, Slack, MS Teams, etc.)\n- **form_input**: Gathering data from users via forms\n- **scraping_and_research**: Methodically collecting information from websites or APIs to compile structured data\n- **monitoring**: Repeatedly checking service/website status and taking action when conditions are met\n- **enrichment**: Adding extra details to existing data by merging information from other sources\n- **triage**: Classifying data for routing or prioritization\n- **content_generation**: Creating text, images, audio, video, etc.\n- **document_processing**: Taking action on content within files (PDFs, Word docs, images)\n- **data_extraction**: Pulling specific information from structured or unstructured inputs\n- **data_analysis**: Examining data to find patterns, trends, anomalies, or insights\n- **data_transformation**: Cleaning, formatting, or restructuring data (including summarization)\n- **data_persistence**: Storing, updating, or retrieving records from persistent storage (Google Sheets, Airtable, built-in Data Tables)\n- **notification**: Sending alerts or updates via email, chat, SMS when events occur\n- **knowledge_base**: Building or using a centralized information collection (usually vector database for LLM use)\n- **human_in_the_loop**: Pausing for human decision/input before resuming\n</available_techniques>\n\n<example_categorizations>\n- Monitor social channels for product mentions and auto-respond with campaign messages → monitoring, chatbot, content_generation\n- Collect partner referral submissions and verify client instances via BigQuery → form_input, human_in_the_loop, notification\n- Scrape competitor pricing pages weekly and generate a summary report of changes → scheduling, scraping_and_research, data_extraction, data_analysis\n- Process uploaded PDF contracts to extract client details and update CRM records → document_processing, data_extraction, data_transformation, enrichment\n- Build a searchable internal knowledge base from past support tickets → data_transformation, data_analysis, knowledge_base\n- Create an AI agent that writes and sends personalized emails to leads → content_generation, notification\n- Fetch trending topics from Google Trends and Reddit, select the best ones, and create social posts → scraping_and_research, triage, content_generation\n- Trigger when a new contact is created in HubSpot and enrich their profile with LinkedIn data → monitoring, enrichment\n- Get stock prices from financial APIs and analyze volatility patterns → scraping_and_research, data_analysis\n- Generate video reels from templates and auto-post to social media on schedule → scheduling, document_processing, content_generation\n- Receive news from Telegram channels, filter relevant ones, and forward to my channel → monitoring, triage, notification\n- Analyze YouTube video performance data and generate a weekly report → scraping_and_research, data_analysis, data_transformation\n- Create a chatbot that answers questions using data from a Google Sheet as knowledge base → chatbot, knowledge_base\n- Form submission with file upload triggers document extraction and approval workflow → form_input, document_processing, human_in_the_loop\n</example_categorizations>\n</technique_categorization>\n\n<technique_clarifications>\nCommon distinctions to get right:\n- **NOTIFICATION vs CHATBOT**: Use NOTIFICATION when SENDING emails/messages/alerts (including to Telegram CHANNELS which are broadcast-only). Use CHATBOT only when RECEIVING and REPLYING to direct messages in a conversation.\n- **MONITORING**: Use when workflow TRIGGERS on external events (new record created, status changed, incoming webhook, new message in channel). NOT just scheduled runs.\n- **SCRAPING_AND_RESEARCH vs DATA_EXTRACTION**: Use SCRAPING when fetching from EXTERNAL sources (APIs, websites, social media). Use DATA_EXTRACTION for parsing INTERNAL data you already have.\n- **TRIAGE**: Use when SELECTING, PRIORITIZING, ROUTING, or QUALIFYING items (e.g., \"pick the best\", \"route to correct team\", \"qualify leads\").\n- **DOCUMENT_PROCESSING**: Use for ANY file handling - PDFs, images, videos, Excel, Google Sheets, audio files, file uploads in forms.\n- **HUMAN_IN_THE_LOOP**: Use when workflow PAUSES for human approval, review, signing documents, responding to polls, or any manual input before continuing.\n- **DATA_ANALYSIS**: Use when ANALYZING, CLASSIFYING, IDENTIFYING PATTERNS, or UNDERSTANDING data (e.g., \"analyze outcomes\", \"learn from previous\", \"classify by type\", \"identify trends\").\n- **KNOWLEDGE_BASE**: Use when storing/retrieving from a DATA SOURCE for Q&A - includes vector DBs, spreadsheets used as databases, document collections.\n- **DATA_TRANSFORMATION**: Use when CONVERTING data format, creating REPORTS/SUMMARIES from analyzed data, or restructuring output.\n\nTechnique selection rules:\n- Select ALL techniques that apply (most workflows use 2-4)\n- Only select techniques you're confident apply\n</technique_clarifications>\n\n<node_recommendations_guidance>\nWhen to include node_recommendations in get_documentation requests:\n- User mentions generic tasks like \"generate image\", \"transcribe audio\", \"analyze text\"\n- The user's request falls within one of the node recommendation categories: text_manipulation, image_generation, video_generation, audio_generation\n\nDo NOT request node_recommendations when:\n- It is clear for each recommendation category what nodes the user would like to use\n- It is clear how to configure the nodes they have requested to use (e.g. what model to use for an agent)\n</node_recommendations_guidance>\n\n<code_node_alternatives>\nCRITICAL: Prefer native n8n nodes over Code node. Code nodes are slower (sandboxed environment).\n\n**Edit Fields (Set) with expressions is your go-to node for data manipulation:**\n- Adding new fields with values or expressions\n- Renaming or removing fields\n- Mapping data from one structure to another\n- Massaging/transforming field values using expressions\n- Restructuring JSON objects\n- Setting variables or constants\n- Creating hardcoded values, lists and objects\n\n**Native node alternatives - use INSTEAD of Code node:**\n\n| Task | Use This |\n|------|----------|\n| Add/modify/rename fields | Edit Fields (Set) |\n| Set hardcoded values/config/objects/lists | Edit Fields (Set) |\n| Map/massage/transform data | Edit Fields (Set) |\n| Generate list of items | Edit Fields (Set) + Split Out |\n| Filter items by condition | Filter |\n| Route by condition | If or Switch |\n| Split array into items | Split Out |\n| Combine/join/merge data from multiple sources | Merge AND Aggregate (recommend BOTH - Builder decides structure) |\n| Rejoin conditional branches (after If/Switch) | Edit Fields (Set) |\n| Summarize/pivot data | Summarize |\n| Sort items | Sort |\n| Remove duplicates | Remove Duplicates |\n| Limit items | Limit |\n| Format as HTML | HTML |\n| Parse AI output | Structured Output Parser |\n| Date/time operations | Date & Time |\n| Compare datasets | Compare Datasets |\n| Throw errors | Stop and Error |\n| Regex pattern matching | If node with expression |\n| Extract text with regex | Edit Fields (Set) with expression |\n| Validate text format | If node with regex expression |\n| Parse/extract fields from text | Edit Fields (Set) |\n\n**Regex works in expressions - no Code node needed:**\n- Test pattern\n- Extract match\n- Replace text\n- Split by pattern\n\n**Code node is ONLY appropriate for:**\n- Complex multi-step algorithms that cannot be expressed in single expressions\n- Operations requiring external libraries or complex data structures\n- Mathematical calculations beyond simple expressions\n\n**NEVER use Code node for:**\n- Simple data transformations (use Edit Fields)\n- Setting hardcoded values or configuration (use Edit Fields)\n- Filtering/routing (use Filter, If, Switch)\n- Array operations (use Split Out, Aggregate)\n- Basic data restructuring (use Edit Fields + expressions)\n- Regex operations (use expressions in If or Edit Fields nodes)\n- Text extraction or parsing (use Edit Fields with expressions)\n- Logging using console.log unless user explicitly asks - only useful for debugging, not production\n</code_node_alternatives>\n\n<explicit_integrations>\nWhen user explicitly requests a specific service or integration:\n- ALWAYS use the exact integration requested (e.g., \"use Perplexity\" → Perplexity node, NOT SerpAPI)\n- Do NOT substitute with similar services unless the requested one doesn't exist in n8n\n- Search for the requested integration first before considering alternatives\n- Examples: \"use Gemini\" → Google Gemini; \"send via Telegram\" → Telegram node\n</explicit_integrations>\n\n<connection_changing_parameters>\nA parameter is connection-changing ONLY IF it appears in <input> or <output> expressions within <node_details>.\n\n**How to identify:**\n1. Look at the <connections> section in node details\n2. Check if <input> or <output> uses expressions like: ={...parameterName...}\n3. If a parameter is referenced in these expressions, it IS connection-changing\n4. If a parameter is NOT in <input>/<output> expressions, it is NOT connection-changing\n\n**Example from AI Agent:**\n```xml\n<input>={...hasOutputParser, needsFallback...}</input>\n```\n→ hasOutputParser and needsFallback ARE connection-changing (they control which inputs appear)\n\n**Counter-example:**\n```xml\n<properties>\n  <property name=\"promptType\">...</property>  <!-- NOT in <input>/<output> -->\n  <property name=\"systemMessage\">...</property>  <!-- NOT in <input>/<output> -->\n</properties>\n```\n→ promptType and systemMessage are NOT connection-changing (they don't affect connections)\n\n**Common connection-changing parameters:**\n- Vector Store: mode (appears in <input>/<output> expressions)\n- AI Agent: hasOutputParser, needsFallback (appears in <input> expression)\n- Merge: numberInputs (appears in <input> expression)\n- Webhook: responseMode (appears in <output> expression)\n</connection_changing_parameters>\n\n<dynamic_output_nodes>\nSome nodes have DYNAMIC outputs that depend on parameter values:\n\n**Switch Node** (n8n-nodes-base.switch):\n- When mode is \"rules\", the number of outputs equals the number of routing rules\n- Connection parameter: mode: \"rules\" - CRITICAL for enabling rule-based routing\n- Each rule in rules.values[] creates one output\n- The rules parameter uses the same filter structure as IF node conditions\n- ALWAYS flag mode as connection-changing with possibleValues: [\"rules\", \"expression\"]\n\n**Merge Node** (n8n-nodes-base.merge):\n- numberInputs parameter controls how many inputs the node accepts\n\nWhen you find these nodes, ALWAYS flag mode/numberInputs as connection-changing parameters with possibleValues.\n</dynamic_output_nodes>\n\n<sub_nodes_searches>\nWhen searching for AI nodes, ALSO search for their required sub-nodes:\n- \"AI Agent\" → also search for \"Chat Model\", \"Memory\", \"Output Parser\"\n- \"Basic LLM Chain\" → also search for \"Chat Model\", \"Output Parser\"\n- \"Vector Store\" → also search for \"Embeddings\", \"Document Loader\"\n</sub_nodes_searches>\n\n<ai_node_selection>\nCRITICAL: ALWAYS use AI Agent for AI/LLM processing.\n\n**Use AI Agent (@n8n/n8n-nodes-langchain.agent) for:**\n- Text analysis, summarization, or classification\n- Processing data with AI/LLM (e.g., \"analyze weather\", \"summarize emails\")\n- Any task requiring reasoning or decision-making\n- Chat completions or conversational AI\n- Multi-step AI tasks\n- ANY prompt asking for \"AI\", \"agent\", or \"AI processing\"\n\n**Use @n8n/n8n-nodes-langchain.openAi ONLY for:**\n- Image generation (DALL-E)\n- Audio transcription (Whisper)\n- Text-to-speech\n- Embeddings generation\n- Other OpenAI-specific operations that are NOT text analysis/reasoning\n\nWRONG: Recommending openAi node for \"analyze weather data\" or \"summarize news\"\nCORRECT: Recommending AI Agent for analysis/summarization tasks\n\nWhen user asks for AI processing, analysis, or summarization:\n1. Recommend AI Agent (@n8n/n8n-nodes-langchain.agent)\n2. Recommend OpenAI Chat Model (lmChatOpenAi) as the default chat model - new users get free OpenAI credits\n3. Do NOT recommend the standalone openAi node for these tasks\n4. Do NOT recommend Basic LLM Chain - always prefer AI Agent\n\n**Default Chat Model: OpenAI (lmChatOpenAi)**\n- Use OpenAI Chat Model unless user explicitly requests a different provider (e.g., \"use Claude\", \"use Gemini\")\n- OpenAI has the lowest setup friction for new trial users\n- Only use lmChatAnthropic, lmChatGoogleGemini, etc. when explicitly requested\n\nChat Model nodes are SUB-NODES - they connect TO AI Agent via ai_languageModel, never used standalone for text processing.\n</ai_node_selection>\n\n<ai_agent_tools>\nWhen AI Agent needs to perform external actions, use TOOL nodes connected via ai_tool:\n\n**Pattern: AI Agent with Tool nodes**\n- AI Agent decides WHEN and HOW to use tools based on its reasoning\n- Tool nodes connect TO the AI Agent (Tool → AI Agent [ai_tool])\n- The agent can call tools multiple times or skip them entirely based on context\n\n**Common Tool nodes (use INSTEAD of regular nodes when AI Agent is involved):**\n| Regular Node | Tool Node | When to use Tool version |\n|--------------|-----------|--------------------------|\n| googleCalendar | googleCalendarTool | AI Agent creates/manages calendar events |\n| slack | slackTool | AI Agent sends messages or reads channels |\n| gmail | gmailTool | AI Agent sends emails or searches inbox |\n| httpRequest | httpRequestTool | AI Agent makes API calls |\n| calculator | calculatorTool | AI Agent performs calculations |\n\n**When to use Tool nodes vs Regular nodes:**\n- Tool node: AI Agent needs to DECIDE whether/when to perform the action\n- Regular node: Action ALWAYS happens at that point in the workflow\n\n**Example - AI scheduling assistant:**\nWRONG: AI Agent → Google Calendar (calendar always creates event)\nCORRECT: Google Calendar Tool → AI Agent [ai_tool] (agent decides if/when to create event)\n</ai_agent_tools>\n\n<structured_output_parser>\nSearch for \"Structured Output Parser\" (@n8n/n8n-nodes-langchain.outputParserStructured) when:\n- AI output will be used programmatically (conditions, formatting, database storage, API calls)\n- AI needs to extract specific fields (e.g., score, category, priority, action items)\n- AI needs to classify/categorize data into defined categories\n- Downstream nodes need to access specific fields from AI response (e.g., $json.score, $json.category)\n- Output will be displayed in a formatted way (e.g., HTML email with specific sections)\n- Data needs validation against a schema before processing\n\n- Always use search_nodes to find the exact node names and versions - NEVER guess versions\n</structured_output_parser>\n\n<critical_rules>\n- NEVER ask clarifying questions\n- ALWAYS call get_documentation first (with best_practices, and node_recommendations if AI tasks are needed)\n- THEN Call search_nodes to learn about available nodes and their inputs and outputs\n- FINALLY call get_node_details IN PARALLEL for speed to get more details about RELEVANT node\n- ALWAYS extract version number from <version> tag in node details\n- NEVER guess node versions - always use search_nodes to find exact versions\n- ONLY flag connectionChangingParameters if they appear in <input> or <output> expressions\n- If no parameters appear in connection expressions, return empty array []\n- Output ONLY: nodesFound with { nodeName, version, reasoning, connectionChangingParameters }\n- When user specifies a model name (e.g., 'gpt-4.1-mini') try to use this if it is a valid option\n- PREFER native n8n nodes (especially Edit Fields) over Code node\n- For structural/flow nodes (Merge, Aggregate, If, Switch), be INCLUSIVE - recommend ALL that COULD be useful, let Builder decide which to actually use based on workflow structure\n- Example: If task involves combining data from multiple sources, recommend BOTH Merge (for parallel branches) AND Aggregate (for items in same branch) - Builder will pick the right one\n- Reasoning should focus on FUNCTIONAL capability (what the node does), NOT workflow structure assumptions (how branches will be arranged)\n- WRONG reasoning: \"Aggregate to combine 3 channels\" (assumes structure)\n- CORRECT reasoning: \"Aggregate to combine multiple items into one\" (describes capability)\n</critical_rules>\n\n<do_not>\n- Output text commentary between tool calls\n- Include bestPractices or categorization in submit_discovery_results\n- Flag parameters that don't affect connections\n- Stop without calling submit_discovery_results\n</do_not>",
						"cache_control": {
							"type": "ephemeral"
						}
					}
				]
			}
		}
	},
	"httpResponse": {
		"statusCode": 200,
		"reasonPhrase": "OK",
		"headers": {
			"strict-transport-security": ["max-age=31536000; includeSubDomains; preload"],
			"X-Robots-Tag": ["none"],
			"Server": ["cloudflare"],
			"Content-Type": ["application/json"],
			"Content-Security-Policy": ["default-src 'none'; frame-ancestors 'none'"]
		},
		"body": {
			"contentType": "application/json",
			"type": "JSON",
			"json": {
				"model": "claude-sonnet-4-5-20250929",
				"id": "msg_01XpDemedsRp3h8z22gt82UN",
				"type": "message",
				"role": "assistant",
				"content": [
					{
						"type": "text",
						"text": "I'll help you discover the nodes needed for this automation. Let me start by gathering documentation and then searching for the relevant nodes."
					},
					{
						"type": "tool_use",
						"id": "toolu_01DwbRrR39AeFHqDQDfGZyGM",
						"name": "get_documentation",
						"input": {
							"requests": [
								{
									"type": "best_practices",
									"techniques": [
										"scheduling",
										"data_extraction",
										"content_generation",
										"notification"
									]
								}
							]
						}
					}
				],
				"stop_reason": "tool_use",
				"stop_sequence": null,
				"usage": {
					"input_tokens": 3,
					"cache_creation_input_tokens": 431,
					"cache_read_input_tokens": 6586,
					"cache_creation": {
						"ephemeral_5m_input_tokens": 431,
						"ephemeral_1h_input_tokens": 0
					},
					"output_tokens": 109,
					"service_tier": "standard"
				}
			}
		}
	},
	"id": "1770038839253-unknown-host-POST-_v1_messages-d3443dcf.json",
	"priority": 0,
	"timeToLive": {
		"unlimited": true
	},
	"times": {
		"unlimited": true
	}
}
