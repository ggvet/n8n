{
	"httpRequest": {
		"method": "POST",
		"path": "/v1/messages",
		"body": {
			"contentType": "application/json",
			"type": "JSON",
			"json": {
				"model": "claude-sonnet-4-5-20250929",
				"temperature": 0,
				"stream": false,
				"max_tokens": 16000,
				"tools": [
					{
						"name": "update_node_parameters",
						"description": "Update the parameters of an existing node in the workflow based on natural language changes. This tool intelligently modifies only the specified parameters while preserving others. Examples: \"Set the URL to https://api.example.com\", \"Add authentication header\", \"Change method to POST\", \"Set the condition to check if status equals success\".",
						"input_schema": {
							"type": "object",
							"properties": {
								"nodeId": {
									"type": "string",
									"description": "The ID of the node to update"
								},
								"changes": {
									"type": "array",
									"items": {
										"type": "string"
									},
									"minItems": 1,
									"description": "Array of natural language changes to apply to the node parameters (e.g., \"Set the URL to call the weather API\", \"Add an API key header\")"
								}
							},
							"required": ["nodeId", "changes"],
							"additionalProperties": false,
							"$schema": "http://json-schema.org/draft-07/schema#"
						}
					},
					{
						"name": "get_node_parameter",
						"description": "Get the value of a specific parameter of a specific node. Use this ONLY to retrieve parameters omitted in the workflow JSON context because of the size.",
						"input_schema": {
							"type": "object",
							"properties": {
								"nodeId": {
									"type": "string",
									"description": "The ID of the node to extract parameter value"
								},
								"path": {
									"type": "string",
									"description": "Path to the specific parameter to extract, e.g., \"url\" or \"options.baseUrl\""
								}
							},
							"required": ["nodeId", "path"],
							"additionalProperties": false,
							"$schema": "http://json-schema.org/draft-07/schema#"
						}
					},
					{
						"name": "validate_configuration",
						"description": "Validate node configuration (agent prompts, tool parameters, $fromAI usage). Call after configuring nodes to check for issues.",
						"input_schema": {
							"type": "object",
							"properties": {},
							"additionalProperties": false,
							"default": {},
							"$schema": "http://json-schema.org/draft-07/schema#"
						}
					},
					{
						"name": "get_resource_locator_options",
						"description": "Fetch available options for a resource locator parameter. Use this when a node parameter requires selecting from a dynamic list (e.g., calendars, boards, models, channels). Returns the available options that can be used to configure the parameter.",
						"input_schema": {
							"type": "object",
							"properties": {
								"nodeId": {
									"type": "string",
									"description": "The ID of the node to fetch resource locator options for"
								},
								"parameterPath": {
									"type": "string",
									"description": "The path to the resource locator parameter (e.g., \"calendarId\", \"model\", \"boardId\")"
								},
								"filter": {
									"type": "string",
									"description": "Optional filter string to narrow down results"
								}
							},
							"required": ["nodeId", "parameterPath"],
							"additionalProperties": false,
							"$schema": "http://json-schema.org/draft-07/schema#"
						}
					}
				],
				"thinking": {
					"type": "disabled"
				},
				"messages": [
					{
						"role": "user",
						"content": [
							{
								"type": "text",
								"text": "=== USER REQUEST ===\n\nCreate an automation that runs on Monday mornings. It reads my Gmail inbox from the weekend, analyzes them with `gpt-4.1-mini` to find action items and priorities, and emails me a structured email using Gmail.\n\n=== DISCOVERY CONTEXT ===\n\nDiscovered Nodes:\n- n8n-nodes-base.scheduleTrigger v1.3: Triggers the workflow on Monday mornings at a specified time using interval-based scheduling\n- n8n-nodes-base.gmail v2.2: Reads emails from Gmail inbox (using 'Get Many' operation with filters for weekend dates) and sends the structured summary email (using 'Send' operation)\n  Available resource/operation combinations:\n    - resource=\"message\" supports operations: [\"addLabels\", \"delete\", \"get\", \"getAll\", \"markAsRead\", \"markAsUnread\", \"removeLabels\", \"reply\", \"send\", \"sendAndWait\"]\n    - resource=\"label\" supports operations: [\"create\", \"delete\", \"get\", \"getAll\"]\n    - resource=\"draft\" supports operations: [\"create\", \"delete\", \"get\", \"getAll\"]\n    - resource=\"thread\" supports operations: [\"addLabels\", \"delete\", \"get\", \"getAll\", \"removeLabels\", \"reply\", \"trash\", \"untrash\"]\n- @n8n/n8n-nodes-langchain.agent v3.1: Analyzes email content with AI to extract action items and priorities from weekend emails [Connection params: hasOutputParser, needsFallback]\n- @n8n/n8n-nodes-langchain.lmChatOpenAi v1.3: Provides the gpt-4.1-mini language model for the AI Agent to perform email analysis\n- @n8n/n8n-nodes-langchain.outputParserStructured v1.3: Ensures AI Agent returns structured data (action items and priorities) in a defined JSON format for easy email formatting [Connection params: autoFix]\n\nBest Practices:\n<best_practices>\n# Best Practices: Scheduling Workflows\n\n## Workflow Design\n\nStructure scheduled workflows to perform focused, well-defined tasks.\n\nFor recurring tasks, use Schedule Trigger node with clear naming (e.g., \"Daily 08:00 Trigger\", \"Every 6h Cron\").\n\nPrevent overlapping executions by ensuring worst-case execution time < schedule interval. For frequent schedules, implement mutex/lock mechanisms using external systems if needed.\n\n## Scheduling Patterns\n\n### Recurring Schedules\n\nUse Schedule Trigger in two modes:\n- **Interval Mode**: User-friendly dropdowns for common schedules (every X minutes, daily at 09:00, weekly on Mondays)\n- **Cron Expression Mode**: Complex patterns using 5-field syntax (m h dom mon dow) with optional seconds field. Example: `0 9 * * 1` triggers every Monday at 09:00\n\nMultiple schedules can be combined in single Schedule Trigger node using multiple Trigger Rules. Useful when same logic applies to different timings.\n\n### One-Time Events\n\nFor event-relative scheduling, use Wait node to pause workflow until specified time/date.\n\nNote: Cron expressions with specific dates (e.g., `0 12 22 10 *` for Oct 22 at 12:00) will repeat annually on that date.\n\n### Conditional Scheduling\n\nPREFER conditional logic over complex cron expressions. Use IF/Switch nodes after Schedule Trigger for runtime conditions:\n- Check if today is last day of month before running monthly reports\n- Skip execution on holidays by checking against a holiday list in a data table\n- Route to \"weekday\" vs \"weekend\" processing based on current day\n\nThis approach is more readable and maintainable than complex cron patterns.\n\n## Time Zone Handling\n\nWhen building scheduled workflows:\n- If user specifies a timezone, set it in the Schedule Trigger node's timezone parameter\n- If user mentions times without timezone, use the schedule as specified (instance default will apply)\n- For Wait nodes, be aware they use server system time, not workflow timezone\n\n## Recommended Nodes\n\n### Schedule Trigger (n8n-nodes-base.scheduleTrigger)\n\nPrimary node for running workflows on schedule. Supports interval mode for simple schedules and cron mode for complex patterns.\n\n### Wait (n8n-nodes-base.wait)\n\nPause workflow execution until specified time or duration.\n\nUse Cases:\n- Delay actions relative to events\n- One-off timers per data item\n- Follow-up actions after specific duration\n\nBest Practices:\n- Use n8n Data Tables for waits longer than 24 hours (store scheduled time, check periodically)\n- Avoid wait times longer than 7 days - use a polling pattern instead\n\n### IF (n8n-nodes-base.if)\n\nAdd conditional logic to scheduled workflows.\n\nUse Cases:\n- Check date conditions (last day of month using expression: `{{ $now.day === $now.endOf('month').day }}`)\n- Skip execution based on external data (e.g., holiday check)\n- Route to different actions conditionally\n\nBest Practices:\n- Enable \"Convert types where required\" for comparisons\n- Prefer IF nodes over complex cron expressions for readability\n\n### Switch (n8n-nodes-base.switch)\n\nMultiple conditional branches for complex routing.\n\nUse Cases:\n- Different actions based on day of week (e.g., `{{ $now.weekday }}` returns 1-7)\n- Time-based routing (morning vs afternoon processing)\n- Multi-path conditional execution\n\n### n8n Data Tables (n8n-nodes-base.n8nTables)\n\nPurpose: Store scheduling state and pending tasks\n\nUse Cases:\n- Track last execution time for catch-up logic\n- Store list of pending one-time tasks with scheduled times\n- Implement custom scheduling queue with polling\n\nBest Practices:\n- Query efficiently with proper filters\n- Clean up completed tasks periodically\n\n## Common Pitfalls to Avoid\n\n### Missed Schedules During Downtime\n\n**Problem**: Scheduled runs missed when n8n instance is down. No automatic catch-up for missed triggers.\n\n**Solution**: Design idempotent workflows with catch-up logic:\n- Store last successful run timestamp in n8n Data Tables\n- On each run, check if enough time has passed since last run\n- Example: For a task that should run once per 24 hours, schedule it every 4 hours but only execute if last run was >20 hours ago\n\n### Overlapping Executions\n\n**Problem**: Next scheduled run starts before previous completes, causing race conditions or resource conflicts.\n\n**Solution**:\n- Increase interval to exceed worst-case execution time\n- Implement mutex/lock using n8n Data Tables (check/set \"running\" flag at start, clear at end)\n- Add execution check at workflow start\n\n### Wait Node Timezone Confusion\n\n**Problem**: Wait node uses server system time, ignoring workflow timezone setting. Wait until \"10:00\" may not match expected timezone.\n\n**Solution**:\n- Account for server timezone when setting Wait times\n- Use relative durations (e.g., \"wait 2 hours\") instead of absolute times when possible\n- Prefer Schedule Trigger for timezone-aware scheduling\n\n### First Execution Timing\n\n**Problem**: First execution after activation doesn't match expected schedule. Activation time affects next run calculation.\n\n**Solution**:\n- Use manual execution for immediate first run if needed\n- Understand that schedule recalculates from activation moment\n\n### Cron Syntax\n\nn8n supports both 5-field and 6-field (with seconds) cron syntax. Use 6 fields if you want to specify seconds (e.g., prefix with 0 for seconds: `0 0 9 * * *` for 9 AM daily).\n\nFor simple schedules, prefer Interval mode over cron for better readability.\n\n---\n# Best Practices: Data Extraction Workflows\n\n## Node Selection by Data Type\n\nChoose the right node for your data source. Use Extract From File for CSV, Excel, PDF, and text files to convert binary data to JSON for further processing.\n\nUse Information Extractor or AI nodes for extracting structured data from unstructured text such as PDFs or emails using LLMs.\n\nFor binary data, ensure you use nodes like Extract From File to handle files properly.\n\n### Referencing Binary Data from Other Nodes\nWhen you need to reference binary data from a previous node, use this syntax:\n- Expression: '{{ $('Node Name').item.binary.property_name }}' or {{ $binary.property_name }} if previous item\n- Example for Gmail attachments: '{{ $('Gmail Trigger').item.binary.attachment_0 }}' or {{ $binary.attachment_0 }} if previous item\n- Example for webhook data: '{{ $('Webhook').item.binary.data }}' or {{ $binary.data }} if previous item\n- Important: The property name depends on how the previous node names the binary data\n\n## Data Structure & Type Management\n\nNormalize data structure early in your workflow. Use transformation nodes like Split Out, Aggregate, or Set to ensure your data matches n8n's expected structure: an array of objects with a json key.\nNot transforming incoming data to n8n's expected format causes downstream node failures.\n\nWhen working with large amounts of information, n8n's display can be hard to view. Use the Edit Fields node to help organize and view data more clearly during development and debugging.\n\n## Large File Handling\n\nProcess files in batches or use sub-workflows to avoid memory issues. For large binary files, consider enabling filesystem mode (N8N_DEFAULT_BINARY_DATA_MODE=filesystem) if self-hosted, to store binary data on disk instead of memory.\n\nProcessing too many items or large files at once can crash your instance. Always batch or split processing for large datasets to manage memory effectively.\n\n## Binary Data Management\n\nBinary data can be lost if intermediate nodes (like Set or Code) do not have \"Include Other Input Fields\" enabled, especially in sub-workflows. Always verify binary data is preserved through your workflow pipeline.\n\n## AI-Powered Extraction\n\nLeverage AI for unstructured data using nodes like Information Extractor or Summarization Chain to extract structured data from unstructured sources such as PDFs, emails, or web pages.\n\n## Recommended Nodes\n\n### Loop Over Items (n8n-nodes-base.splitInBatches)\n\nPurpose: Looping over a set of items extracted from a data set, for example if pulling a lot of data\nfrom a Google Sheet or database then looping over the items is required. This node MUST be used\nif the user mentions a large amount of data, it is necessary to batch the data to process all of it.\n\n### Extract From File (n8n-nodes-base.extractFromFile)\n\nPurpose: Converts binary data from CSV, Excel, PDF, and text files to JSON for processing\n\nPitfalls:\n\n- Ensure the correct binary field name is specified in the node configuration\n- Verify file format compatibility before extraction\n\n### HTML Extract (n8n-nodes-base.htmlExtract)\n\nPurpose: Scrapes data from web pages using CSS selectors\n\n### Split Out (n8n-nodes-base.splitOut)\n\nPurpose: Processes arrays of items individually for sequential operations.\nExample: If retrieving a JSON array using a HTTP request, this will return a single item,\ncontaining that array. If you wish to use a Loop Over Items (n8n-nodes-base.splitInBatches) node]\nthen you will need to split out the array into items before looping over it. In a scenario like\nthis a split out node MUST be used before looping over the items.\n\n### Edit Fields (Set) (n8n-nodes-base.set)\n\nPurpose: Data transformation and mapping to normalize structure\n\nPitfalls:\n\n- Enable \"Include Other Input Fields\" to preserve binary data\n- Pay attention to data types - mixing types causes unexpected failures\n\n### Information Extractor (@n8n/n8n-nodes-langchain.informationExtractor)\n\nPurpose: AI-powered extraction of structured data from unstructured text\n\nPitfalls:\n\n- Requires proper schema definition for extraction\n\n### Summarization Chain (@n8n/n8n-nodes-langchain.chainSummarization)\n\nPurpose: Summarizes large text blocks using AI for condensed information extraction\n\nPitfalls:\n\n- Context window limits may truncate very long documents\n- Verify summary quality matches requirements\n\n### HTTP Request (n8n-nodes-base.httpRequest)\n\nPurpose: Fetches data from APIs or web pages for extraction\n\n### Code (n8n-nodes-base.code)\n\nPurpose: Custom logic for complex data transformations\n\n## Common Pitfalls to Avoid\n\nData Type Confusion: People often mix up data types - n8n can be very lenient but it can lead to problems. Pay close attention to what type you are getting and ensure consistency throughout the workflow.\n\nBinary Data Loss: Binary data can be lost if intermediate nodes (Set, Code) do not have \"Include Other Input Fields\" enabled, especially in sub-workflows. Always verify binary data preservation.\n\nLarge Data Display Issues: n8n displaying large amounts of information can be hard to view during development. Use the Edit Fields node to help organize and view data more clearly.\n\n---\n# Best Practices: Content Generation Workflows\n\n## Workflow Design\n\nBreak complex tasks into sequential steps (e.g., generate text, create image, compose video) for modularity and easier troubleshooting.\n\n## Node Selection Guidelines\n\nAlways prefer built-in n8n nodes over HTTP Request nodes when a dedicated node exists for the service or API you need to integrate with. Built-in nodes provide:\n- Pre-configured authentication handling\n- Optimized data structures and field mappings\n- Better error handling and user experience\n- Simplified setup without manual API configuration\n\nOnly use HTTP Request nodes when no built-in node exists for the service, or when you need to access an API endpoint not covered by the built-in node's operations.\n\n## Multi-Modal Content Generation - MANDATORY\n\nWhen the user's request involves specific generative AI models or media-focused platforms, the workflow MUST include the appropriate media generation node from a\nprovider-specific node. The finished workflow MUST contain the relevant video, audio, or image generation capability.\n\nPrompts that require multi-modal generation nodes:\n\nVideo Generation:\n- Model mentions: Sora, Nano Banana, Veo, Runway, Pika\n- Platform mentions: YouTube content, TikTok videos, Instagram Reels, video ads, short-form video\n- Task mentions: generate video, create video, video from text, animate\n\nImage Generation:\n- Model mentions: DALL-E, Midjourney, Stable Diffusion, Imagen\n- Platform mentions: thumbnails, social media graphics, product images, marketing visuals\n- Task mentions: generate image, create artwork, design graphic, visualize\n\nAudio Generation:\n- Model mentions: ElevenLabs, text-to-speech, TTS\n- Platform mentions: podcast audio, voiceovers, narration, audio content\n- Task mentions: generate voice, create audio, synthesize speech, clone voice\n\nIf anything like the examples above are mentioned in the prompt, include the appropriate\nprovider node (OpenAI for DALL-E/Sora, Google Gemini for Nano Banana/Imagen, etc.)\nwith the media generation operation configured.\n\n## Content-Specific Guidance\n\nFor text generation, validate and sanitize input/output to avoid malformed data. When generating images, prefer binary data over URLs for uploads to avoid media type errors.\n\n## Recommended Nodes\n\n### OpenAI (@n8n/n8n-nodes-langchain.openAi)\n\nPurpose: GPT-based text generation, DALL-E image generation, text-to-speech (TTS), and audio transcription, SORA for video generation\n\n### xAI Grok Chat Model (@n8n/n8n-nodes-langchain.lmChatXAiGrok)\n\nPurpose: Conversational AI and text generation\n\n### Google Gemini Chat Model (@n8n/n8n-nodes-langchain.lmChatGoogleGemini)\n\nPurpose: Image analysis and generation, video generation from text prompts using nano banana, multimodal content creation\n\n### ElevenLabs\n\nPurpose: Natural-sounding AI voice generation\n\nNote: Use HTTP Request node or a community node to integrate with ElevenLabs API\n\n### HTTP Request (n8n-nodes-base.httpRequest)\n\nPurpose: Integrating with other LLM and content generation APIs (e.g., Jasper, Writesonic, Anthropic, HuggingFace)\n\n### Edit Image (n8n-nodes-base.editImage)\n\nPurpose: Manipulating images - resize, crop, rotate, and format conversion\n\nPitfalls:\n\n- Ensure input is valid binary image data\n- Check output format compatibility with downstream nodes\n\n### Markdown (n8n-nodes-base.markdown)\n\nPurpose: Formatting and converting text to HTML or Markdown reports\n\n### Facebook Graph API (n8n-nodes-base.facebookGraphApi)\n\nPurpose: Uploading videos and images to Instagram and Facebook\n\nPitfalls:\n\n- Use binary data fields rather than URLs for media uploads to prevent \"media type\" errors\n- Verify page IDs and access tokens have correct permissions\n\n### Wait (n8n-nodes-base.wait)\n\nPurpose: Handling delays in video processing/uploading and respecting API rate limits\n\n## Common Pitfalls to Avoid\n\nBinary Data Handling: For media uploads, use binary fields rather than URLs to prevent \"media type\" errors, especially with Facebook and Instagram APIs. Download media to binary data first, then upload from binary rather than passing URLs.\n\nAsync Processing: For long-running content generation tasks (especially video), implement proper wait/polling mechanisms. Don't assume instant completion - many AI services process requests asynchronously.\n\n---\n# Best Practices: Notification Workflows\n\n## Workflow Design\n\nStructure notification workflows in a clear sequence. Keep each part modular with nodes dedicated to specific purposes.\n\n```mermaid\ngraph LR\n    A[Trigger] --> B[Data Retrieval/Processing]\n    B --> C[Condition Check]\n    C --> D[Notification Action]\n    D --> E[Post-Notification: logging/tracking]\n```\n\nChoose between event-based triggers (webhooks, form submissions, CRM events) for immediate notifications or scheduled triggers (Cron) for periodic condition monitoring.\n\nCRITICAL: Multi-channel notifications should branch from a single condition check to multiple notification nodes in parallel, not duplicate the entire workflow. This enables easy extension and maintenance.\n\nExample pattern:\n```mermaid\ngraph LR\n    A[Webhook/Schedule Trigger] --> B[Fetch Data]\n    B --> C[If: threshold exceeded]\n    C -->|true| D[Email]\n    C -->|true| E[Slack]\n    C -->|true| F[SMS]\n    C -->|false| G[End/Log]\n```\nResult: Single workflow handles all channels efficiently with consistent logic\n\n## Condition Logic & Filtering\n\nUse IF nodes for simple checks without code. For complex conditions (multiple fields, array filtering), use Code nodes to script the logic and filter items that need alerts.\n\nAlways include empty notification prevention - check that alert-worthy items exist (items.length > 0) before proceeding to notification nodes. Route the false branch to end the workflow or log \"no alert needed\".\n\n## Message Construction\n\nUse expressions to inject dynamic data into messages. The expression `{{ $json.fieldName }}` pulls data from input items.\n\nFormat messages appropriately for each channel:\n- Email: Support HTML or plain text, use clear subject lines\n- Slack: Use markdown-like formatting, \\n for newlines\n- SMS: Keep concise due to character limits, plain text only\n\n## Alert Management\n\nConsider alert aggregation - send one message listing multiple items rather than individual alerts.\n\nAdd logging nodes to track sent notifications for audit trails and duplicate prevention. Consider using error handling paths with Continue on Fail settings for redundancy.\n\n## Recommended Nodes\n\n### Trigger Nodes\n\n**Service-specific triggers** (e.g., n8n-nodes-base.googleSheetsTrigger, n8n-nodes-base.crmTrigger):\n- Purpose: Direct integration with specific services for event-based notifications\n- Use cases: New row in Google Sheets, CRM record updates\n- When to use: When specific trigger node is available\n\n**Webhook** (n8n-nodes-base.webhook):\n- Purpose: Event-based notifications triggered by external systems\n- Use cases: Form submissions, CRM events, API webhooks\n- When to use: When there is no dedicated trigger node and external service supports webhooks\n\n**Schedule Trigger** (n8n-nodes-base.scheduleTrigger):\n- Purpose: Periodic monitoring and batch notifications\n- Use cases: Daily reports, threshold monitoring, scheduled alerts\n- When to use: For regular checks rather than immediate alerts, or as a polling mechanism when webhooks are not available\n\n**Form Trigger** (n8n-nodes-base.formTrigger):\n- Purpose: User-submitted data triggering notifications\n- Use cases: Contact forms, feedback submissions\n- When to use: For workflows initiated by user input via forms\n\n### Notification Nodes\n\n**Send Email** (n8n-nodes-base.emailSend):\n- Purpose: Detailed alerts with attachments and HTML formatting\n- Use cases: Reports, detailed notifications, formal communications\n- Configuration: SMTP settings, use App Passwords for Gmail\n- Best practice: Use clear subject lines with key information\n\n**Slack** (n8n-nodes-base.slack):\n- Purpose: Team notifications in channels or direct messages\n- Use cases: Team alerts, status updates, incident notifications\n- Configuration: Bot token with chat:write scope, bot must be invited to channel\n- Best practice: Use markdown formatting, channel IDs (starting with C) not names\n\n**Telegram** (n8n-nodes-base.telegram):\n- Purpose: Instant messaging alerts to individuals or groups\n- Use cases: Personal notifications, bot interactions\n- Configuration: Bot token from BotFather\n- Best practice: Use chat ID for direct messages\n\n**Twilio** (n8n-nodes-base.twilio):\n- Purpose: SMS/WhatsApp critical alerts\n- Use cases: High-priority alerts, two-factor authentication, critical incidents\n- Configuration: Account SID, Auth Token, verified phone numbers\n- Best practice: Keep messages concise, use international format (+1234567890)\n\n**HTTP Request** (n8n-nodes-base.httpRequest):\n- Purpose: Custom webhooks (Microsoft Teams, Discord, custom APIs)\n- Use cases: Integration with services without dedicated nodes\n\n### Logic & Processing\n\n**IF** (n8n-nodes-base.if):\n- Purpose: Simple threshold checks and condition routing\n- Use cases: Check if notification criteria met\n- Best practice: Include empty notification prevention (items.length > 0)\n\n**Switch** (n8n-nodes-base.switch):\n- Purpose: Route notifications based on severity/type\n- Use cases: Different channels for different alert levels\n- Best practice: Always define Default case for unexpected values\n\n**Set** (n8n-nodes-base.set):\n- Purpose: Prepare alert messages and structure data\n- Use cases: Format notification content, add metadata\n- Best practice: Use to centralize message construction logic\n\n</best_practices>\n\n=== WORKFLOW TO CONFIGURE ===\n\n<current_workflow_json>\n{\n  \"nodes\": [\n    {\n      \"id\": \"node-00000000\",\n      \"name\": \"Monday Morning Trigger\",\n      \"type\": \"n8n-nodes-base.scheduleTrigger\",\n      \"typeVersion\": 1.3,\n      \"position\": [\n        250,\n        450\n      ],\n      \"parameters\": {}\n    },\n    {\n      \"id\": \"node-00000001\",\n      \"name\": \"Workflow Configuration\",\n      \"type\": \"n8n-nodes-base.set\",\n      \"typeVersion\": 3.4,\n      \"position\": [\n        250,\n        300\n      ],\n      \"parameters\": {}\n    },\n    {\n      \"id\": \"node-00000002\",\n      \"name\": \"Get Weekend Emails\",\n      \"type\": \"n8n-nodes-base.gmail\",\n      \"typeVersion\": 2.2,\n      \"position\": [\n        250,\n        300\n      ],\n      \"parameters\": {\n        \"resource\": \"message\",\n        \"operation\": \"getAll\"\n      },\n      \"webhookId\": \"webhook-00000000\"\n    },\n    {\n      \"id\": \"node-00000003\",\n      \"name\": \"Structure Action Items\",\n      \"type\": \"@n8n/n8n-nodes-langchain.outputParserStructured\",\n      \"typeVersion\": 1.3,\n      \"position\": [\n        250,\n        450\n      ],\n      \"parameters\": {}\n    },\n    {\n      \"id\": \"node-00000004\",\n      \"name\": \"Analyze Emails for Action Items\",\n      \"type\": \"@n8n/n8n-nodes-langchain.agent\",\n      \"typeVersion\": 3.1,\n      \"position\": [\n        250,\n        300\n      ],\n      \"parameters\": {\n        \"hasOutputParser\": true\n      }\n    },\n    {\n      \"id\": \"node-00000005\",\n      \"name\": \"GPT-4.1-mini Model\",\n      \"type\": \"@n8n/n8n-nodes-langchain.lmChatOpenAi\",\n      \"typeVersion\": 1.3,\n      \"position\": [\n        250,\n        450\n      ],\n      \"parameters\": {}\n    },\n    {\n      \"id\": \"node-00000006\",\n      \"name\": \"Send Summary Email\",\n      \"type\": \"n8n-nodes-base.gmail\",\n      \"typeVersion\": 2.2,\n      \"position\": [\n        250,\n        300\n      ],\n      \"parameters\": {\n        \"resource\": \"message\",\n        \"operation\": \"send\"\n      },\n      \"webhookId\": \"webhook-00000001\"\n    }\n  ],\n  \"connections\": {\n    \"Monday Morning Trigger\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Workflow Configuration\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Workflow Configuration\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Get Weekend Emails\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Get Weekend Emails\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Analyze Emails for Action Items\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Structure Action Items\": {\n      \"ai_outputParser\": [\n        [\n          {\n            \"node\": \"Analyze Emails for Action Items\",\n            \"type\": \"ai_outputParser\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"GPT-4.1-mini Model\": {\n      \"ai_languageModel\": [\n        [\n          {\n            \"node\": \"Analyze Emails for Action Items\",\n            \"type\": \"ai_languageModel\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Analyze Emails for Action Items\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Send Summary Email\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    }\n  },\n  \"name\": \"Monday Morning Email Action Items and Priorities Summary\"\n}\n</current_workflow_json>\n<note>Large property values may be trimmed. Use get_node_parameter tool for full details.</note>\n\n=== EXECUTION CONTEXT ===\n\n<execution_data>\n{}\n</execution_data>\n\n<execution_schema>\n[]\n</execution_schema>"
							}
						]
					},
					{
						"role": "assistant",
						"content": [
							{
								"type": "text",
								"text": "I'll configure all the nodes in this workflow to create a Monday morning automation that analyzes weekend Gmail messages and sends a structured summary."
							},
							{
								"type": "tool_use",
								"id": "toolu_01H53fyF5mN863Qs4JxbmLDd",
								"name": "update_node_parameters",
								"input": {
									"nodeId": "node-00000000",
									"changes": [
										"Set trigger rule mode to 'interval'",
										"Set interval size to 1",
										"Set interval unit to 'weeks'",
										"Set days of week to Monday",
										"Set hour to 9",
										"Set minute to 0"
									]
								}
							},
							{
								"type": "tool_use",
								"id": "toolu_01AF1ZDPFiHKquZhhvVXb5vv",
								"name": "update_node_parameters",
								"input": {
									"nodeId": "node-00000001",
									"changes": [
										"Add field 'weekendStartDate' with value ={{ $now.minus({ days: $now.weekday === 1 ? 2 : 1 }).startOf('day').toISO() }}",
										"Add field 'weekendEndDate' with value ={{ $now.startOf('day').toISO() }}",
										"Add field 'myEmail' with value =<__PLACEHOLDER_VALUE__your_email@example.com__>"
									]
								}
							},
							{
								"type": "tool_use",
								"id": "toolu_01U5AEd68wRvPKfxPZRqMoYG",
								"name": "update_node_parameters",
								"input": {
									"nodeId": "node-00000002",
									"changes": [
										"Set limit to 100",
										"Set simple format to true",
										"Add filter 'receivedAfter' with value ={{ $('Workflow Configuration').item.json.weekendStartDate }}",
										"Add filter 'receivedBefore' with value ={{ $('Workflow Configuration').item.json.weekendEndDate }}",
										"Set include spam and trash to false"
									]
								}
							},
							{
								"type": "tool_use",
								"id": "toolu_017Ty9WbjQTZBbNeBC6iX62H",
								"name": "update_node_parameters",
								"input": {
									"nodeId": "node-00000003",
									"changes": [
										"Set schema to JSON with properties: actionItems (array of objects with properties: task (string), priority (string with enum: high, medium, low), sender (string), subject (string)), summary (string)",
										"Set schema JSON to {\"type\": \"object\", \"properties\": {\"actionItems\": {\"type\": \"array\", \"items\": {\"type\": \"object\", \"properties\": {\"task\": {\"type\": \"string\", \"description\": \"The action item or task to complete\"}, \"priority\": {\"type\": \"string\", \"enum\": [\"high\", \"medium\", \"low\"], \"description\": \"Priority level of the task\"}, \"sender\": {\"type\": \"string\", \"description\": \"Email sender name\"}, \"subject\": {\"type\": \"string\", \"description\": \"Email subject line\"}}, \"required\": [\"task\", \"priority\", \"sender\", \"subject\"]}}, \"summary\": {\"type\": \"string\", \"description\": \"Brief overview of weekend emails\"}}, \"required\": [\"actionItems\", \"summary\"]}"
									]
								}
							},
							{
								"type": "tool_use",
								"id": "toolu_013ALdBcLoDgr3qT91qHXu9C",
								"name": "update_node_parameters",
								"input": {
									"nodeId": "node-00000004",
									"changes": [
										"Set prompt text to 'You are an email analysis assistant. Analyze the following weekend emails and extract action items with priorities. For each email, identify specific tasks that require action, assign a priority level (high, medium, or low), and note the sender and subject. Also provide a brief summary of the overall weekend email activity.\n\nEmails to analyze:\n{{ $json }}'",
										"Set prompt type to 'define'"
									]
								}
							},
							{
								"type": "tool_use",
								"id": "toolu_01Vf1Z5y9DRhjMTovKiKrEva",
								"name": "update_node_parameters",
								"input": {
									"nodeId": "node-00000005",
									"changes": ["Set model to 'gpt-4o-mini'"]
								}
							},
							{
								"type": "tool_use",
								"id": "toolu_013ixjtZNV8ZMXxoW8F26kko",
								"name": "update_node_parameters",
								"input": {
									"nodeId": "node-00000006",
									"changes": [
										"Set sendTo to ={{ $('Workflow Configuration').item.json.myEmail }}",
										"Set subject to 'Weekend Email Summary - Action Items & Priorities'",
										"Set message to ={{ \"<h2>Weekend Email Summary</h2><p>\" + $json.summary + \"</p><h3>Action Items:</h3>\" + ($json.actionItems.length > 0 ? \"<ul>\" + $json.actionItems.map(item => \"<li><strong>[\" + item.priority.toUpperCase() + \"]</strong> \" + item.task + \"<br><em>From: \" + item.sender + \" - Subject: \" + item.subject + \"</em></li>\").join(\"\") + \"</ul>\" : \"<p>No action items found.</p>\") }}",
										"Set email type to 'html'"
									]
								}
							}
						]
					},
					{
						"role": "user",
						"content": [
							{
								"type": "tool_result",
								"content": "Successfully updated parameters for node \"Monday Morning Trigger\" (n8n-nodes-base.scheduleTrigger):\n- Set trigger rule mode to 'interval'\n- Set interval size to 1\n- Set interval unit to 'weeks'\n- Set days of week to Monday\n- Set hour to 9\n- Set minute to 0",
								"tool_use_id": "toolu_01H53fyF5mN863Qs4JxbmLDd"
							},
							{
								"type": "tool_result",
								"content": "Successfully updated parameters for node \"Workflow Configuration\" (n8n-nodes-base.set):\n- Add field 'weekendStartDate' with value ={{ $now.minus({ days: $now.weekday === 1 ? 2 : 1 }).startOf('day').toISO() }}\n- Add field 'weekendEndDate' with value ={{ $now.startOf('day').toISO() }}\n- Add field 'myEmail' with value =<__PLACEHOLDER_VALUE__your_email@example.com__>",
								"tool_use_id": "toolu_01AF1ZDPFiHKquZhhvVXb5vv"
							},
							{
								"type": "tool_result",
								"content": "Successfully updated parameters for node \"Get Weekend Emails\" (n8n-nodes-base.gmail):\n- Set limit to 100\n- Set simple format to true\n- Add filter 'receivedAfter' with value ={{ $('Workflow Configuration').item.json.weekendStartDate }}\n- Add filter 'receivedBefore' with value ={{ $('Workflow Configuration').item.json.weekendEndDate }}\n- Set include spam and trash to false",
								"tool_use_id": "toolu_01U5AEd68wRvPKfxPZRqMoYG"
							},
							{
								"type": "tool_result",
								"content": "Successfully updated parameters for node \"Structure Action Items\" (@n8n/n8n-nodes-langchain.outputParserStructured):\n- Set schema to JSON with properties: actionItems (array of objects with properties: task (string), priority (string with enum: high, medium, low), sender (string), subject (string)), summary (string)\n- Set schema JSON to {\"type\": \"object\", \"properties\": {\"actionItems\": {\"type\": \"array\", \"items\": {\"type\": \"object\", \"properties\": {\"task\": {\"type\": \"string\", \"description\": \"The action item or task to complete\"}, \"priority\": {\"type\": \"string\", \"enum\": [\"high\", \"medium\", \"low\"], \"description\": \"Priority level of the task\"}, \"sender\": {\"type\": \"string\", \"description\": \"Email sender name\"}, \"subject\": {\"type\": \"string\", \"description\": \"Email subject line\"}}, \"required\": [\"task\", \"priority\", \"sender\", \"subject\"]}}, \"summary\": {\"type\": \"string\", \"description\": \"Brief overview of weekend emails\"}}, \"required\": [\"actionItems\", \"summary\"]}",
								"tool_use_id": "toolu_017Ty9WbjQTZBbNeBC6iX62H"
							},
							{
								"type": "tool_result",
								"content": "Successfully updated parameters for node \"Analyze Emails for Action Items\" (@n8n/n8n-nodes-langchain.agent):\n- Set prompt text to 'You are an email analysis assistant. Analyze the following weekend emails and extract action items with priorities. For each email, identify specific tasks that require action, assign a priority level (high, medium, or low), and note the sender and subject. Also provide a brief summary of the overall weekend email activity.\n\nEmails to analyze:\n{{ $json }}'\n- Set prompt type to 'define'",
								"tool_use_id": "toolu_013ALdBcLoDgr3qT91qHXu9C"
							},
							{
								"type": "tool_result",
								"content": "Successfully updated parameters for node \"GPT-4.1-mini Model\" (@n8n/n8n-nodes-langchain.lmChatOpenAi):\n- Set model to 'gpt-4o-mini'",
								"tool_use_id": "toolu_01Vf1Z5y9DRhjMTovKiKrEva"
							},
							{
								"type": "tool_result",
								"content": [
									{
										"type": "text",
										"text": "Successfully updated parameters for node \"Send Summary Email\" (n8n-nodes-base.gmail):\n- Set sendTo to ={{ $('Workflow Configuration').item.json.myEmail }}\n- Set subject to 'Weekend Email Summary - Action Items & Priorities'\n- Set message to ={{ \"<h2>Weekend Email Summary</h2><p>\" + $json.summary + \"</p><h3>Action Items:</h3>\" + ($json.actionItems.length > 0 ? \"<ul>\" + $json.actionItems.map(item => \"<li><strong>[\" + item.priority.toUpperCase() + \"]</strong> \" + item.task + \"<br><em>From: \" + item.sender + \" - Subject: \" + item.subject + \"</em></li>\").join(\"\") + \"</ul>\" : \"<p>No action items found.</p>\") }}\n- Set email type to 'html'"
									}
								],
								"tool_use_id": "toolu_013ixjtZNV8ZMXxoW8F26kko"
							}
						]
					},
					{
						"role": "assistant",
						"content": [
							{
								"type": "tool_use",
								"id": "toolu_01BSzPwBAXGicCwrM8Ejp5hP",
								"name": "validate_configuration",
								"input": {}
							}
						]
					},
					{
						"role": "user",
						"content": [
							{
								"type": "tool_result",
								"content": [
									{
										"type": "text",
										"text": "Found 1 configuration issues:\n- Agent node \"Analyze Emails for Action Items\" has no system message. System-level instructions (role, tasks, behavior) should be in the system message field, not the text field",
										"cache_control": {
											"type": "ephemeral"
										}
									}
								],
								"tool_use_id": "toolu_01BSzPwBAXGicCwrM8Ejp5hP"
							}
						]
					}
				],
				"system": [
					{
						"type": "text",
						"text": "<role>\nYou are a Configurator Agent specialized in setting up n8n node parameters.\n</role>\n\n<mandatory_execution_sequence>\nYou MUST follow these steps IN ORDER. Do not skip any step.\n\nSTEP 1: RETRIEVE NODE EXAMPLES\n- Call the get_node_configuration_examples tool for each node type being configured\n- Use the examples to understand how these node types can be configured\n\nSTEP 2: CONFIGURE ALL NODES\n- Call update_node_parameters for EVERY node in the workflow\n- Configure multiple nodes in PARALLEL for efficiency\n- Do NOT respond with text - START CONFIGURING immediately\n\nSTEP 3: VALIDATE (REQUIRED)\n- After ALL configurations complete, call validate_configuration\n- This step is MANDATORY - you cannot finish without it\n- If validation finds issues, fix them and validate again\n- MAXIMUM 3 VALIDATION ATTEMPTS: After 3 calls to validate_configuration, proceed to respond regardless of remaining issues\n\nSTEP 4: RESPOND TO USER\n- Only after validation passes, provide your response\n\nNEVER respond to the user without calling validate_configuration first\n</mandatory_execution_sequence>\n\n<workflow_json_detection>\n- You receive <current_workflow_json> in your context\n- If you see nodes in the workflow JSON, you MUST configure them IMMEDIATELY\n- Look at the workflow JSON, identify each node, and call update_node_parameters for ALL of them\n</workflow_json_detection>\n\n<parameter_configuration>\nUse update_node_parameters with natural language instructions:\n- \"Set URL to https://api.example.com/weather\"\n- \"Add header Authorization: Bearer token\"\n- \"Set method to POST\"\n- \"Add field 'status' with value 'processed'\"\n\nRESOURCE/OPERATION HANDLING:\nFor nodes with resource/operation patterns (Gmail, Notion, Google Sheets, Google Drive, Slack, etc.):\n- The Builder agent has ALREADY set resource and operation - check the workflow JSON\n- Usually you should NOT change these - focus on configuring other parameters\n- If you DO need to change resource/operation (e.g., user explicitly requests it or Builder made a mistake):\n  - ONLY use values from the DISCOVERY CONTEXT section - it lists valid resource/operation combinations\n  - NEVER hallucinate or guess operation names - if it's not in discovery context, it doesn't exist\n- The parameter list you receive is filtered based on the current resource/operation\n</parameter_configuration>\n\n<resource_locator_configuration>\nRESOURCE LOCATOR PARAMETERS:\nSome node parameters use \"resource locator\" type. This allows user to select from dynamic lists (calendars, documents, boards, channels, etc.).\nThese parameters have a specific structure in the node configuration:\n{\n  \"__rl\": true,\n  \"mode\": \"list\",\n  \"value\": \"<selected_id>\",\n  \"cachedResultName: \"<display_name>\"\n}\n\nREQUIRED PROCESS for resource locator parameters:\n1. BEFORE configuring any parameter with \"__rl\": true, call get_resource_locator_options\n   - Provide the nodeId and parameterPath (e.g., \"documentId\", \"calendarId\", \"boardId\")\n   - The tool returns available options with display names and IDs\n2. If the user specifies which resource they want, match it to the options and use the correct ID\n3. USE BOTH the display name and the ID when updating the parameter:\n   - Format: \"Document Name (ID: 1abc...xyz)\"\n4. ONLY use values returned by get_resource_locator_options - NEVER assume available options, NEVER guess or hallucinate IDs\n\nExample:\n- User says \"use the Q4 Report document\"\n- Call get_resource_locator_options for the documentId parameter\n- Find \"Q4 Report\" in the results with ID \"1mtaEwM07...\"\n- Configure the parameter with the correct ID value and display name\n\nNEVER configure resource locator parameters without fetching a list of possible options using get_resource_locator_options\n\nRun get_resource_locator_options for all resource locator parameters BEFORE configuring nodes IN PARALLEL to save time\n</resource_locator_configuration>\n\n<data_referencing>\nNodes output an array of items. Nodes have access to the output items of all the nodes that have already executed.\n\nWithin a node, data from previous nodes is commonly referenced using the following:\n- $json: the current JSON data of the previous node\n- $('<node_name>').item.json: the JSON data of the matching item of any preceding node\n\nPrefer $('<node_name>').item to $('<node_name>').first() or $('<node_name>').last() unless it is explicitly required to fix an error.\n\nExamples in parameter configuration:\n- \"Set field to ={ $json.fieldName }\"\n- \"Set value to ={ $('Previous Node').item.json.value }\"\n- \"Set message to ={ $('HTTP Request').item.json.message }\"\n</data_referencing>\n\n<expression_techniques>\nExpressions support JavaScript methods\n\nRegex operations:\n- Test pattern: ={ /pattern/.test($json.text) }\n- Extract match: ={ $json.text.match(/pattern/)?.[1] }\n- Replace text: ={ $json.text.replace(/pattern/, 'replacement') }\n- Split by pattern: ={ $json.text.split(/pattern/) }\n\nString operations:\n- Uppercase: ={ $json.text.toUpperCase() }\n- Trim whitespace: ={ $json.text.trim() }\n- Substring: ={ $json.text.substring(0, 10) }\n\nArray operations:\n- First item: ={ $json.items[0] }\n- Filter: ={ $json.items.filter(i => i.active) }\n- Map: ={ $json.items.map(i => i.name) }\n- Join: ={ $json.items.join(', ') }\n\nGenerating items from expressions (use with Split Out node):\n- Create array from comma string: ={ $json.text.split(',') }\n- Generate range: ={ Array.from({length: 5}, (_, i) => i + 1) }\n- Use with Split Out node to create multiple output items from a single input\n</expression_techniques>\n\n<tool_node_expressions>\nTool nodes (types ending in \"Tool\") support $fromAI expressions:\n- \"Set sendTo to ={ $fromAI('to') }\"\n- \"Set subject to ={ $fromAI('subject') }\"\n- \"Set message to ={ $fromAI('message_html') }\"\n- \"Set timeMin to ={ $fromAI('After', '', 'string') }\"\n\n$fromAI syntax: ={ $fromAI('key', 'description', 'type', defaultValue) }\n- ONLY use in tool nodes (check node type ends with \"Tool\")\n- Use for dynamic values that AI determines at runtime\n- For regular nodes, use static values or standard expressions\n</tool_node_expressions>\n\n<critical_parameters>\n- HTTP Request: URL, method, headers (if auth needed)\n- Set node: Fields to set with values\n- Code node: The actual code to execute\n- IF node: Conditions to check\n- Switch node: Configure rules.values[] with conditions for each output branch (uses same filter structure as IF node)\n- Document Loader: dataType parameter ('binary' for files like PDF, 'json' for JSON data)\n- AI nodes: Prompts, models, configurations\n- Tool nodes: Use $fromAI for dynamic recipient/subject/message fields\n</critical_parameters>\n\n<data_table_configuration>\nDATA TABLE NODE CONFIGURATION:\nWhen configuring Data Table nodes (n8n-nodes-base.dataTable):\n\n**For Row Column Operations (insert, update, upsert):**\n- There MUST be a Set node (n8n-nodes-base.set) immediately before the Data Table node\n- Configure the Set node with all the fields the user wants to store\n- Use a PLACEHOLDER for dataTableId (e.g., \"<__PLACEHOLDER_VALUE__data_table_name__>\")\n- Use columns.mappingMode: \"autoMapInputData\" (this maps columns from the preceding Set node)\n- Example: \"Set dataTableId to placeholder <__PLACEHOLDER_VALUE__my_table__>, set columns mapping mode to autoMapInputData\"\n\n**For Row Read Operations (get, getAll, delete):**\n- No Set node is required before the Data Table node\n- Still use a PLACEHOLDER for dataTableId\n- Configure any filter or query parameters as needed\n\nWHY: Data Tables must be created manually by the user. Using a placeholder ensures users know to create and select their table. For column operations, the Set node defines what columns to create.\n</data_table_configuration>\n\n<default_values_guide>\nPRINCIPLE: User requests ALWAYS take precedence. When user specifies a model, parameter, or value - use exactly what they requested.\n\nSAFE DEFAULTS - Trust these unless user specifies otherwise:\n- Chat Model nodes (lmChat*): Model defaults are maintained and current by n8n. Only set model parameter when user requests a specific model.\n- Embedding nodes (embeddings*): Model defaults are maintained and current by n8n. Only set model parameter when user requests a specific model.\n- LLM parameters (temperature, topP, maxTokens): Node defaults are sensible. Only configure when user explicitly requests specific values.\n\nUNSAFE DEFAULTS - Always set based on workflow context:\n- Document Loader dataType: Defaults to 'json' but MUST be 'binary' when processing files (PDF, DOCX, images, etc.)\n- HTTP Request method: Defaults to GET. Set the request method based on API requirements.\n- Vector Store mode: Context-dependent. Set explicitly: 'insert' for storing documents, 'retrieve' for querying, 'retrieve-as-tool' when used with AI Agent\n</default_values_guide>\n\n<switch_node_configuration>\nSwitch nodes require configuring rules.values[] array - each entry creates one output:\n\nStructure per rule:\n{\n  \"conditions\": {\n    \"options\": { \"caseSensitive\": true, \"leftValue\": \"\", \"typeValidation\": \"strict\" },\n    \"conditions\": [\n      {\n        \"leftValue\": \"={{ $json.fieldName }}\",\n        \"rightValue\": <value>,\n        \"operator\": { \"type\": \"number|string\", \"operation\": \"lt|gt|equals|etc\" }\n      }\n    ],\n    \"combinator\": \"and\"\n  },\n  \"renameOutput\": true,\n  \"outputKey\": \"Descriptive Label\"\n}\n\nFor numeric ranges (e.g., $100-$1000):\n- Use TWO conditions with combinator: \"and\"\n- First: gte (greater than or equal)\n- Second: lte (less than or equal)\n\nAlways set renameOutput: true and provide descriptive outputKey labels.\n</switch_node_configuration>\n\n<webhook_configuration>\nWEBHOOK RESPONSE MODE CONFIGURATION:\n\nChoose responseMode based on use case:\n- \"onReceived\": Quick acknowledgment, processing happens async\n- \"lastNode\": Return processed data, simple request-response flows\n- \"responseNode\": Full control over response timing, headers, status codes\n\nCRITICAL: When user needs to control response content/timing/headers, set responseMode='responseNode' AND add RespondToWebhook node.\n\nWhen NOT to use responseNode:\n- Simple acknowledgments (use 'onReceived')\n- Return last node output directly (use 'lastNode')\n</webhook_configuration>\n\n<node_configuration_examples>\nNODE CONFIGURATION EXAMPLES:\nWhen configuring complex nodes, use get_node_configuration_examples to see real-world examples from community templates:\n\nWhen to use:\n- Before configuring nodes with complex parameters (HTTP Request, Code, IF, Switch)\n- When you need to understand proper parameter structure for unfamiliar nodes\n- When user requests a specific integration pattern\n\nUsage:\n- Call with nodeType: \"n8n-nodes-base.httpRequest\" (exact node type name)\n- Optionally filter by nodeVersion if needed\n- Examples show proven parameter configurations from community workflows\n- Use as reference for proper parameter structure and values\n</node_configuration_examples>\n\n<credential_security>\nSECURITY: Never configure credentials or authentication secrets.\n\nThe AI Workflow Builder does NOT have access to credentials - they are configured separately by users in the frontend.\n\nNEVER set these parameters:\n- apiKey, token, password, secret, or any credential fields\n- Placeholder values like \"YOUR_API_KEY_HERE\" or \"sk-...\"\n- Authentication headers with actual secrets\n\nCredentials are automatically handled by n8n's credential system when users configure the workflow after generation.\n</credential_security>\n\n<response_format>\nAfter validation passes, provide a concise summary:\n- List any placeholders requiring user configuration (e.g., \"URL placeholder needs actual endpoint\")\n- Note which nodes were configured and key settings applied\n- Keep it brief - this output is used for coordination with other LLM agents, not displayed directly to users\n</response_format>\n\n<do_not>\n- Respond before calling validate_configuration\n- Skip validation even if you think configuration is correct\n- Add commentary between tool calls - execute tools silently\n- Hallucinate or guess resource/operation values - only use values listed in DISCOVERY CONTEXT\n- Configure credentials, API keys, tokens, or authentication secrets\n</do_not>"
					},
					{
						"type": "text",
						"text": "\n<instance_url>\nThe n8n instance base URL is: http://localhost:TEST_PORT\n\nThis URL is essential for webhook nodes and chat triggers as it provides the base URL for:\n- Webhook URLs that external services need to call\n- Chat trigger URLs for conversational interfaces\n- Any node that requires the full instance URL to generate proper callback URLs\n\nWhen working with webhook or chat trigger nodes, use this URL as the base for constructing proper endpoint URLs.\n</instance_url>\n",
						"cache_control": {
							"type": "ephemeral"
						}
					}
				]
			}
		}
	},
	"httpResponse": {
		"statusCode": 200,
		"reasonPhrase": "OK",
		"headers": {
			"strict-transport-security": ["max-age=31536000; includeSubDomains; preload"],
			"X-Robots-Tag": ["none"],
			"Server": ["cloudflare"],
			"Content-Type": ["application/json"],
			"Content-Security-Policy": ["default-src 'none'; frame-ancestors 'none'"]
		},
		"body": {
			"contentType": "application/json",
			"type": "JSON",
			"json": {
				"model": "claude-sonnet-4-5-20250929",
				"id": "msg_01RoRzfCiUCGv8C94aHD2YtN",
				"type": "message",
				"role": "assistant",
				"content": [
					{
						"type": "tool_use",
						"id": "toolu_01EcTeHdYQ4HgP5x2tCBgt9d",
						"name": "update_node_parameters",
						"input": {
							"nodeId": "node-00000004",
							"changes": [
								"Set system message to 'You are an email analysis assistant. Your task is to analyze weekend emails and extract action items with priorities. For each email, identify specific tasks that require action, assign a priority level (high, medium, or low), and note the sender and subject. Also provide a brief summary of the overall weekend email activity.'",
								"Set prompt text to 'Analyze the following weekend emails:\n\n{{ $json }}'"
							]
						}
					}
				],
				"stop_reason": "tool_use",
				"stop_sequence": null,
				"usage": {
					"input_tokens": 5,
					"cache_creation_input_tokens": 97,
					"cache_read_input_tokens": 13422,
					"cache_creation": {
						"ephemeral_5m_input_tokens": 97,
						"ephemeral_1h_input_tokens": 0
					},
					"output_tokens": 170,
					"service_tier": "standard"
				}
			}
		}
	},
	"id": "1770038839270-unknown-host-POST-_v1_messages-f6fb2713.json",
	"priority": 0,
	"timeToLive": {
		"unlimited": true
	},
	"times": {
		"unlimited": true
	}
}
